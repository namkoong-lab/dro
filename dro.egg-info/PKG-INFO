Metadata-Version: 2.1
Name: dro
Version: 0.2.0
Summary: A package of distributionally robust optimization (DRO) methods. Implemented via cvxpy and PyTorch
Home-page: https://github.com/namkoong-lab/dro
Author: DRO developers.
Author-email: liujiashuo77@gmail.com, tw2837@columbia.edu
License: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: MacOS
Classifier: Operating System :: POSIX :: Linux
Requires-Python: >=3
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: pandas
Requires-Dist: numpy>=1.20
Requires-Dist: scikit-learn
Requires-Dist: torch
Requires-Dist: scipy
Requires-Dist: cvxpy
Requires-Dist: torchvision
Requires-Dist: ucimlrepo
Requires-Dist: matplotlib
Requires-Dist: torchattacks

## DRO: A Python Package for Distributionally Robust Optimization in Machine Learning

`DRO` is a python package that implements typical DRO methods on linear loss (SVM, logistic regression, and linear regression) for supervised learning tasks. It is built based on the convex optimization solver `cvxpy`. Without specified, our DRO model is to solve the following optimization problem:
$$\min_{\theta} \max_{P: P \in U} E_{(X,Y) \sim P}[\ell(\theta;(X, Y))],$$
where $U$ is the so-called ambiguity set and typically of the form $U = \{P: d(P, \hat P_n) \leq \epsilon\}$ and $\hat P_n := \frac{1}{n}\sum_{i = 1}^n \delta_{(X_i, Y_i)}$ is the empirical distribution of training samples $\{(X_i, Y_i)\}_{i = 1}^n$. And $\epsilon$ is the hyperparameter. 

## Base Models
Currently we have (kernelized) linear models, including logistic regression, linear SVM, and linear regression ($\ell_1$, $\ell_2$ loss) and neural networks.

## Install

```
pip install dro
```

#### Documentation
Please refer to https://python-dro.org for more details!
