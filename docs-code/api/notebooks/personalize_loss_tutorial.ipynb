{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalized Loss\n",
    "In the following, we present a case to show how to incorporate the personalized loss and plug it into different DRO losses based on cvxpy and pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Solver\n",
    "### $f$-divergence DRO\n",
    "Across $f$-divergence DRO, the adaptive loss can be easily modified as follows. Below, we modify the standard loss into the quantile regression:\n",
    "$\\ell((\\theta, b);(X, Y)) = 3(Y - \\theta^{\\top}X - b)^+ + (\\theta^{\\top}X + b - Y)^+$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'theta': [-0.48891007299787476, 0.0], 'b': array(1.9556403)}\n",
      "{'theta': [-0.47103180655319055, 0.0], 'b': array(1.88412725)}\n",
      "{'theta': [-0.4651670885530432, 0.0], 'b': array(1.86066836)}\n",
      "{'theta': [-0.4620192279713162, 0.0], 'b': array(1.84807691)}\n",
      "{'theta': [-0.4599744797040242, 0.0], 'b': array(1.83989792)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/dro/src/linear_model/base.py:61: UserWarning: Unsupported model_type: quantile. Default supported types are svm, logistic, ols, lad. Please define your personalized loss.\n",
      "  warnings.warn(f\"Unsupported model_type: {model_type}. Default supported types are svm, logistic, ols, lad. Please define your personalized loss.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "from dro.src.linear_model.wasserstein_dro import *\n",
    "from dro.src.linear_model.chi2_dro import *\n",
    "X = np.array([[1, 1], [2, 1], [3, 1], [4,1]])\n",
    "y = np.array([1, 1, 0, 0])\n",
    "model = Chi2DRO(input_dim = 2, model_type = 'quantile')\n",
    "\n",
    "\n",
    "from types import MethodType\n",
    "\n",
    "def _loss(self, X, y):\n",
    "    return 3 * np.maximum(y - X @ self.theta - self.b, 0) + np.maximum(X @ self.theta + self.b - y, 0)\n",
    "\n",
    "def _cvx_loss(self, X, y, theta, b):\n",
    "    return 3 * cp.pos(y - X @ theta - b) + 1 * cp.pos(X @ theta + b - y)\n",
    "\n",
    "model._loss = MethodType(_loss, model)\n",
    "model._cvx_loss = MethodType(_cvx_loss, model)\n",
    "for k in range(5):\n",
    "    model.update({'eps': 0.05 * (k + 1)})\n",
    "    print(model.fit(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wasserstein DRO\n",
    "To adjust Wasserstein DRO, besides modifying the `_cvx_loss` (and ``_loss``) functions, we also need to modify the `_penalization` function to adjust the regularization component, where the regularization part denotes the additional part besides the empirical objective. More specifically, in the previous quantile regression example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import MethodType\n",
    "def _penalization(self, theta):\n",
    "    theta_K = theta\n",
    "    if self.p == 1:\n",
    "        dual_norm = np.inf\n",
    "    elif self.p != 'inf':\n",
    "        dual_norm = 1 / (1 - 1 / self.p)\n",
    "    else:\n",
    "        dual_norm = 1\n",
    "    if self.kappa == 'inf':\n",
    "        return 3 * cp.norm(self.cost_inv_transform @ theta_K, dual_norm)\n",
    "    else:\n",
    "        return cp.maximum(cp.norm(self.cost_inv_transform @ theta_K, dual_norm), 1 / self.kappa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small eps {'theta': [-0.5000000000064543, -8.42946033492792e-09], 'b': array(2.00000001)}\n",
      "large eps {'theta': [-0.4999999999261157, 1.1546461152356625e-07], 'b': array(1.99999988)}\n"
     ]
    }
   ],
   "source": [
    "from dro.linear_model.wasserstein_dro import *\n",
    "X = np.array([[1, 1], [2, 1], [3, 1], [4,1]])\n",
    "y = np.array([1, 1, 0, 0])\n",
    "\n",
    "model = WassersteinDRO(input_dim = 2, model_type = 'quantile')\n",
    "model._loss = MethodType(_loss, model)\n",
    "model._cvx_loss = MethodType(_cvx_loss, model)\n",
    "# additional adjustment for the penalization function\n",
    "model._penalization = MethodType(_penalization, model)\n",
    "\n",
    "model.update({'eps': 0.05})\n",
    "print('small eps', model.fit(X, y))\n",
    "\n",
    "model.update({'eps': 0.1})\n",
    "print('large eps', model.fit(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Approximation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
